# 0xRIP 后端 AI 接入逻辑（LLM / VLM / Voice）

本文档约定：如何通过 **OpenAI 兼容接口** 接入 LLM、VLM、Voice，让引导仪式与各场景更**拟人、有温度**，并明确**什么场景用哪种模型**。

→ 前端 UI 与场景：[Frontend - ui](../frontend/ui.md)  
→ 灵魂与 people 设定：[Story - soul](../story/soul.md)

---

## 一、接口标准与能力对应

统一使用 **OpenAI 兼容 API**（可对接 OpenAI、Azure OpenAI、本地部署的 compatible 端点等），便于切换厂商与模型。

| 能力 | OpenAI 对应 API | 在 0xRIP 中的用途 |
|:---|:---|:---|
| **LLM** | `POST /v1/chat/completions` | 引导旁白、墓志铭生成、幽灵对话、意图解析 |
| **VLM** | `POST /v1/chat/completions`（带 `image_url` 的 message）或 `POST /v1/visions/...`（视厂商） | 分析上传的图片/截图、为「所见」生成描述或悼词 |
| **Voice (TTS)** | `POST /v1/audio/speech` | 引导仪式旁白、幽灵「开口说话」、仪式步骤朗读 |
| **Voice (STT)** | `POST /v1/audio/transcriptions` | 语音输入指令、口述记忆入棺、招魂时语音对话 |

后端需封装一层 **统一 AI 网关**：根据场景选择模型与 API，对前端暴露简单 RPC（如 `ritual.guide`、`epitaph.generate`、`ghost.chat`、`ghost.speak` 等），内部再映射到上述接口。

---

## 二、引导仪式（Guidance Ritual）——让进入更有「人味」

引导仪式 = 用户**第一次进入 0xRIP**，或**第一次执行 BURY/SUMMON** 时，系统以「仪式引导者」的身份带领用户完成步骤，而不是冷冰冰的表格与按钮。

### 2.1 目标

- **拟人**：像一位守墓人/向导在对你说话，语气克制、带一点仪式感，而非说明书口吻。
- **有趣**：根据用户行为（如拖入的文件类型、是否犹豫）做**轻度分支**，让每次进入略有不同。
- **可听可读**：关键句子既可看（LLM 生成文案），也可听（Voice TTS），增强沉浸感。

### 2.2 引导仪式中 LLM / VLM / Voice 的分工

| 环节 | 建议模型 | 用法说明 |
|:---|:---|:---|
| **开场白** | LLM + Voice(TTS) | LLM 根据「是否首次访问」生成 1～3 句开场（例：「你来了。这里没有活人，只有被记住的。」）。可选：用 TTS 读出来，声线偏沉、语速稍慢。 |
| **选择棺材类型** | LLM | 用户看到 4 种棺材时，LLM 为每种生成一句**短解释**（不是干巴巴的「标准压缩包」，而是「.zip 棺：凡俗之躯，归于一处」这类）。可带随机变体，避免每次一样。 |
| **撰写墓志铭** | LLM / VLM | 见下节「埋葬仪式」。 |
| **确认死亡前** | LLM + Voice(TTS) | 最后一步前，LLM 生成一句**确认语**（例：「一旦落棺，它就不再属于桌面。你确定吗？」）。重要节点用 TTS 读出，强化仪式感。 |
| **用户犹豫/长时间无操作** | LLM | 若检测到用户在某一 step 停留过久，可触发一句**温和追问**（LLM）：「需要再想想吗？这里没有倒计时。」 |

**结论：引导仪式以 LLM 为主（生成所有旁白与选项文案），关键节点用 Voice TTS 朗读；VLM 仅在用户上传图片/截图作为「遗物」时参与（见埋葬仪式）。**

---

## 三、各场景与模型选型总表

| 场景 | 主要模型 | 次要/可选 | 说明 |
|:---|:---|:---|:---|
| **引导仪式**（开场、选棺、确认死亡） | LLM | Voice(TTS) | 旁白与选项文案用 LLM；关键句 TTS 读出。 |
| **埋葬仪式**（墓志铭生成、文件理解） | LLM | VLM, Voice(TTS) | 文本/结构化数据用 LLM 生成墓志铭；若上传图为「遗物」则用 VLM 看图写悼词；可选 TTS 读墓志铭。 |
| **步骤 4：上传记忆与资料**（id 生成后） | LLM | — | 用户上传私有 .txt 或填入网页 URL；后端抓取 URL 内容后调 LLM 处理（摘要、去噪、结构化），生成该灵魂**独有的 .txt** 存入该墓碑。 |
| **时间线加工「此人一生」**（点击墓碑展示） | LLM | — | 将该墓碑内所有记忆、资料与模型生成的 txt 作为输入，LLM 按时间线编排、润色，生成「此人一生」时间线视图所需的结构化数据或段落，供前端展示。 |
| **招魂 / 幽灵对话** | LLM | Voice(TTS), Voice(STT) | 对话由 LLM + people/ 记忆驱动；可选幽灵「开口」用 TTS、用户语音输入用 STT。 |
| **墓地漫游**（悬停/点击墓碑的短描述） | LLM | — | 根据墓志铭 + 元数据生成一句氛围化短句，LLM 即可。 |
| **自然语言指令解析**（如 `/bury 我的初恋聊天记录`） | LLM | — | 意图+实体抽取，LLM 做 NLU，再映射到 BURY + 参数。 |
| **午夜梦话 / 幽灵主动发言** | LLM | Voice(TTS) | 定时或随机触发，LLM 基于该灵魂记忆生成一句「梦话」，可选 TTS 播报。 |

---

## 四、场景细化与调用约定

### 4.1 引导仪式（详细）

- **输入**：当前步骤 `step`、是否首次 `is_first_visit`、可选上下文（如已选棺材类型、已填写的简短意图）。
- **输出**：一段 1～3 句的旁白文案；若该节点启用 TTS，同时返回「是否朗读」及建议的 voice_id。
- **LLM 系统提示词方向**：角色为「0xRIP 守墓人/引导者」，语气冷静、略带诗意、避免玩笑话；输出简短，避免长段；可带少量随机（如从 2～3 种开场白中选一）。

### 4.2 埋葬仪式：墓志铭生成

- **纯文本/结构化文件**：用 **LLM**。输入 = 文件内容摘要或关键片段（注意长度与隐私），输出 = 一行「代码式悼词」，如 `while(alive) { love++; } // 最终迭代于2023-11-04`，或 64 字符内的中文墓志铭。
- **图片/截图作为遗物**：用 **VLM**。输入 = 图片 + 简短 prompt（「用一句话为这张图写墓志铭，风格：代码感或诗意，不超过 64 字」），输出 = 墓志铭文案。
- **混合**：若用户同时上传文本+图，可 LLM 与 VLM 各生成一版，再由 LLM 做一句融合，或让用户二选一。

### 4.3 招魂 / 幽灵对话

- **主能力**：**LLM**。  
  - 请求中注入该灵魂的 `people/<id>` 信息：`description`、`traits`、`memories` 等（以 system 或 context message 形式）。  
  - 用户消息 + 对话历史送入 `chat/completions`，生成「亡灵人格」的回复，便于**一起讨论曾共同经历的事**。
- **拟人增强**：  
  - **Voice(TTS)**：将幽灵的某句回复转为语音播放（可选用偏中性的「亡灵」声线），增强「在与 ta 说话」的体验。  
  - **Voice(STT)**：用户用麦克风说话，STT 转文字后送入 LLM，实现语音对谈。

### 4.4 自然语言指令解析

- 用户输入如：`/bury 我的初恋聊天记录`、`召唤张三`。  
- **LLM** 做意图识别 + 槽位抽取，输出结构化结果，例如：  
  `{ "intent": "BURY", "target": "我的初恋聊天记录" }` 或 `{ "intent": "SUMMON", "target": "张三" }`。  
- 后端根据 intent 调对应流程（埋葬/招魂等），target 用于匹配文件或 person_id。

### 4.5 记忆与资料：URL 处理与时间线加工（步骤 4 与点击墓碑）

- **id 生成后的引导上传**（对应 UI 步骤 4）：  
  - **私有 .txt 上传**：直接存入该墓碑 id 下，无需模型。  
  - **网页 URL**：后端抓取 URL 正文（可配合爬虫或 Readability 类抽取），将纯文本送入 **LLM**，做摘要、去噪、结构化（如按段落或按主题），输出一份**该灵魂独有的 .txt**，存入该墓碑。便于后续与用户上传的 txt 一起参与「此人一生」的生成。  
- **点击墓碑：时间线加工**：  
  - 输入 = 该墓碑 id 下的所有内容（用户上传的 txt + URL 经模型生成的 txt + 墓志铭等元数据）。  
  - **LLM** 任务：识别时间信息（日期、年份、模糊时间），按时间线排序并分段；可适当润色或生成简短小标题，输出**按时间线编排的「此人一生」**（结构化 JSON 或 Markdown），供前端以时间线形式展示。  
  - 若内容中无明确时间，可由 LLM 按主题/段落分组，或标注为「未标注年代」。

---

## 五、后端模块建议

便于实现与维护，建议拆成以下逻辑模块（可与 API 路由一一对应）：

| 模块 | 职责 | 调用的 AI 能力 |
|:---|:---|:---|
| **RitualGuide** | 引导仪式旁白与选项文案 | LLM，可选 TTS |
| **Epitaph** | 墓志铭生成（文本/图） | LLM，VLM（当输入为图时） |
| **MemoryIngest** | 步骤 4：URL 抓取 + 模型处理，生成独有 txt 入碑 | LLM |
| **TimelineLife** | 点击墓碑：将该碑内记忆/资料加工为「此人一生」时间线 | LLM |
| **GhostChat** | 招魂后的多轮对话 | LLM，可选 TTS/STT |
| **GhostUtter** | 幽灵单句发言（如午夜梦话） | LLM，可选 TTS |
| **NLParser** | 自然语言指令 → intent + 参数 | LLM |
| **TombDesc** | 墓地漫游时墓碑/灵魂的短描述 | LLM |

统一通过 **OpenAI 兼容网关** 调用，网关内根据配置选择模型（如 `gpt-4o` / `gpt-4o-mini` 用于对话，`gpt-4o` 或专用 vision 模型用于 VLM，`tts-1` / `tts-1-hd` 用于 TTS 等）。

---

## 六、配置与安全

- **API Key**：不写死在前端，由后端环境变量注入（如 `OPENAI_API_KEY` 或 `OPENAI_COMPATIBLE_BASE_URL` + `API_KEY`）。
- **用量与降级**：引导仪式、墓志铭等可优先用较小/便宜模型；幽灵对话等长上下文可用更强模型。可配置「无 Key 时降级为固定文案」，保证无 API 时仍可走通流程。
- **隐私**：上传文件内容若送 LLM/VLM，需在隐私政策与用户同意中说明；敏感内容可先本地摘要再只送摘要给模型。

---

## 七、小结：什么场景用什么模型

- **引导仪式拟人化**：全程 **LLM** 生成旁白与选项文案，关键节点用 **Voice(TTS)** 朗读；**VLM** 仅在用户上传图片作为遗物时用于看图写墓志铭。
- **埋葬仪式**：**LLM** 负责墓志铭（文本），**VLM** 负责看图写悼词，**TTS** 可选读墓志铭或确认语。
- **招魂/幽灵对话**：**LLM** 为核心（people/ 记忆注入），**TTS** 让幽灵「开口」，**STT** 支持用户语音输入。
- **其余**：意图解析、墓碑短描述、午夜梦话等，均以 **LLM** 为主，需要「出声」时加 **TTS**。

按上述分工接入标准 OpenAI 接口，即可在不大改前端的前提下，让引导仪式和整体体验更有人味、更可听可对话。后续可在本文档基础上补充具体 prompt 模板与 API 路由设计。
